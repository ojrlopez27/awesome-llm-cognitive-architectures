@article{tomasic:2021,
  title={Propositional Reasoning via Neural Transformer Language Models},
  author={Tomasic, Anthony and Romero, Oscar J and Zimmerman, John and Steinfeld, Aaron},
  journal={Int. Workshop on Neural-Symbolic Learning and Reasoning (NESY)},
  year={2021}
}


@article{wang:2023,
  title={Voyager: An open-ended embodied agent with large language models},
  author={Wang, Guanzhi and Xie, Yuqi and Jiang, Yunfan and Mandlekar, Ajay and Xiao, Chaowei and Zhu, Yuke and Fan, Linxi and Anandkumar, Anima},
  journal={arXiv preprint arXiv:2305.16291},
  year={2023}
}


@misc{yao:2023tree,
      title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models}, 
      author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
      year={2023},
      eprint={2305.10601},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{talebirad:2023,
      title={Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents}, 
      author={Yashar Talebirad and Amirhossein Nadiri},
      year={2023},
      eprint={2306.03314},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}


@article{lecun:2022,
  title={A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27},
  author={LeCun, Yann},
  journal={Open Review},
  volume={62},
  year={2022}
}


@article{du:2023,
  title={Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author={Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B and Mordatch, Igor},
  journal={arXiv preprint arXiv:2305.14325},
  year={2023}
}

@book{minsky:1988,
  title={Society of mind},
  author={Minsky, Marvin},
  year={1988},
  publisher={Simon and Schuster}
}

@article{hesslow:2012,
  title={The current status of the simulation theory of cognition},
  author={Hesslow, Germund},
  journal={Brain research},
  volume={1428},
  pages={71--79},
  year={2012},
  publisher={Elsevier}
}

@article{shanahan:2006,
  title={A cognitive architecture that combines internal simulation with a global workspace},
  author={Shanahan, Murray},
  journal={Consciousness and cognition},
  volume={15},
  number={2},
  pages={433--449},
  year={2006},
  publisher={Elsevier}
}

@misc{actr:2023,
  title        = "Unit 1:  Understanding Production Systems",
  author       = "{ACT-R Website.}",
  howpublished = "\url{http://act-r.psy.cmu.edu/wordpress/wp-content/themes/ACT-R/tutorials/unit1.htm}",
  year         = 2015,
  note         = "Accessed: 2023-08-03"
}



@article{caufield:2023,
  title={Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using zero-shot learning},
  author={Caufield, J Harry and Hegde, Harshad and Emonet, Vincent and Harris, Nomi L and Joachimiak, Marcin P and Matentzoglu, Nicolas and Kim, HyeongSik and Moxon, Sierra AT and Reese, Justin T and Haendel, Melissa A and others},
  journal={arXiv preprint arXiv:2304.02711},
  year={2023}
}

@article{yang:2023,
  title={Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation},
  author={Yang, Yuan and Xiong, Siheng and Payani, Ali and Shareghi, Ehsan and Fekri, Faramarz},
  journal={arXiv preprint arXiv:2305.15541},
  year={2023}
}


@article{zhu:2023,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}


@inproceedings{romero:2021,
    title = "A Task-Oriented Dialogue Architecture via Transformer Neural Language Models and Symbolic Injection",
    author = "Romero, Oscar J.  and
      Wang, Antian  and
      Zimmerman, John  and
      Steinfeld, Aaron  and
      Tomasic, Anthony",
    booktitle = "Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue",
    month = jul,
    year = "2021",
    address = "Singapore and Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.sigdial-1.46",
    pages = "438--444"    
}



@article{pavlick:2023,
  title={Symbols and grounding in large language models},
  author={Pavlick, Ellie},
  journal={Philosophical Transactions of the Royal Society A},
  volume={381},
  number={2251},
  pages={20220041},
  year={2023},
  publisher={The Royal Society}
}


@misc{zhang:2022,
      title={Automatic Chain of Thought Prompting in Large Language Models}, 
      author={Zhuosheng Zhang and Aston Zhang and Mu Li and Alex Smola},
      year={2022},
      eprint={2210.03493},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{binz:2023,
  title={Using cognitive psychology to understand GPT-3},
  author={Binz, Marcel and Schulz, Eric},
  journal={Proceedings of the National Academy of Sciences},
  volume={120},
  number={6},
  pages={e2218523120},
  year={2023},
  publisher={National Acad Sciences}
}


@inproceedings{venkit:2022,
    title = "A Study of Implicit Bias in Pretrained Language Models against People with Disabilities",
    author = "Venkit, Pranav Narayanan  and
      Srinath, Mukund  and
      Wilson, Shomir",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.113",
    pages = "1324--1332",
    abstract = "Pretrained language models (PLMs) have been shown to exhibit sociodemographic biases, such as against gender and race, raising concerns of downstream biases in language technologies. However, PLMs{'} biases against people with disabilities (PWDs) have received little attention, in spite of their potential to cause similar harms. Using perturbation sensitivity analysis, we test an assortment of popular word embedding-based and transformer-based PLMs and show significant biases against PWDs in all of them. The results demonstrate how models trained on large corpora widely favor ableist language.",
}

@article{lieto:2018,
    title = {The knowledge level in cognitive architectures: Current limitations and possible developments},
    journal = {Cognitive Systems Research},
    volume = {48},
    pages = {39-55},
    year = {2018},
    note = {Cognitive Architectures for Artificial Minds},
    issn = {1389-0417},
    doi = {https://doi.org/10.1016/j.cogsys.2017.05.001},
    url = {https://www.sciencedirect.com/science/article/pii/S1389041716302121},
    author = {Antonio Lieto and Christian Lebiere and Alessandro Oltramari},
    keywords = {Knowledge representation, Cognitive architectures, Knowledge heterogeneity, Knowledge processing},
    abstract = {In this paper we identify and characterize an analysis of two problematic aspects affecting the representational level of cognitive architectures (CAs), namely: the limited size and the homogeneous typology of the encoded and processed knowledge. We argue that such aspects may constitute not only a technological problem that, in our opinion, should be addressed in order to build artificial agents able to exhibit intelligent behaviors in general scenarios, but also an epistemological one, since they limit the plausibility of the comparison of the CAs’ knowledge representation and processing mechanisms with those executed by humans in their everyday activities. In the final part of the paper further directions of research will be explored, trying to address current limitations and future challenges.}
}

@inproceedings{scialom:2022,
  title={Fine-tuned language models are continual learners},
  author={Scialom et al., Tom},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={6107--6122},
  year={2022}
}


@inproceedings{bender:2021,
    author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
    title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
    year = {2021},
    isbn = {9781450383097},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3442188.3445922},
    doi = {10.1145/3442188.3445922},
    abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
    booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
    pages = {610–623},
    numpages = {14},
    location = {Virtual Event, Canada},
    series = {FAccT '21}
}

@inproceedings{weidinger:2022,
    author = {Weidinger, Laura and Uesato, Jonathan and Rauh, Maribeth and Griffin, Conor and Huang, Po-Sen and Mellor, John and Glaese, Amelia and Cheng, Myra and Balle, Borja and Kasirzadeh, Atoosa and Biles, Courtney and Brown, Sasha and Kenton, Zac and Hawkins, Will and Stepleton, Tom and Birhane, Abeba and Hendricks, Lisa Anne and Rimell, Laura and Isaac, William and Haas, Julia and Legassick, Sean and Irving, Geoffrey and Gabriel, Iason},
    title = {Taxonomy of Risks Posed by Language Models},
    year = {2022},
    isbn = {9781450393522},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3531146.3533088},
    doi = {10.1145/3531146.3533088},
    abstract = {Responsible innovation on large-scale Language Models (LMs) requires foresight into and in-depth understanding of the risks these models may pose. This paper develops a comprehensive taxonomy of ethical and social risks associated with LMs. We identify twenty-one risks, drawing on expertise and literature from computer science, linguistics, and the social sciences. We situate these risks in our taxonomy of six risk areas: I. Discrimination, Hate speech and Exclusion, II. Information Hazards, III. Misinformation Harms, IV. Malicious Uses, V. Human-Computer Interaction Harms, and VI. Environmental and Socioeconomic harms. For risks that have already been observed in LMs, the causal mechanism leading to harm, evidence of the risk, and approaches to risk mitigation are discussed. We further describe and analyse risks that have not yet been observed but are anticipated based on assessments of other language technologies, and situate these in the same taxonomy. We underscore that it is the responsibility of organizations to engage with the mitigations we discuss throughout the paper. We close by highlighting challenges and directions for further research on risk evaluation and mitigation with the goal of ensuring that language models are developed responsibly.},
    booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
    pages = {214–229},
    numpages = {16},
    keywords = {responsible AI, language models, risk assessment, technology risks, responsible innovation},
    location = {Seoul, Republic of Korea},
    series = {FAccT '22}
}

@article{qian:2022,
  title={Limitations of language models in arithmetic and symbolic induction},
  author={Qian, Jing and Wang, Hong and Li, Zekun and Li, Shiyang and Yan, Xifeng},
  journal={arXiv preprint arXiv:2208.05051},
  year={2022}
}

@article{welleck:2019,
  title={Neural text generation with unlikelihood training},
  author={Welleck, Sean and Kulikov, Ilia and Roller, Stephen and Dinan, Emily and Cho, Kyunghyun and Weston, Jason},
  journal={arXiv preprint arXiv:1908.04319},
  year={2019}
}


@misc{ratner:2023,
      title={Parallel Context Windows for Large Language Models}, 
      author={Nir Ratner and Yoav Levine and Yonatan Belinkov and Ori Ram and Inbal Magar and Omri Abend and Ehud Karpas and Amnon Shashua and Kevin Leyton-Brown and Yoav Shoham},
      year={2023},
      eprint={2212.10947},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@article{kotseruba:2020,
  title={40 years of cognitive architectures: core cognitive abilities and practical applications},
  author={Kotseruba, Iuliia and Tsotsos, John K},
  journal={Artificial Intelligence Review},
  volume={53},
  number={1},
  pages={17--94},
  year={2020},
  publisher={Springer}
}


@article{franklin:2006,
  title={The LIDA architecture: Adding new modes of learning to an intelligent, autonomous, software agent},
  author={Franklin, Stan and Patterson, FG},
  journal={pat},
  volume={703},
  pages={764--1004},
  year={2006}
}

@book{sun:2016,
  title={Anatomy of the mind: exploring psychological mechanisms and processes with the Clarion cognitive architecture},
  author={Sun, Ron},
  year={2016},
  publisher={Oxford University Press}
}

@book{laird:2019,
  title={The Soar cognitive architecture},
  author={Laird, John E},
  year={2019},
  publisher={MIT press}
}

@book{anderson:2014,
  title={The atomic components of thought},
  author={Anderson, John R and Lebiere, Christian J},
  year={2014},
  publisher={Psychology Press}
}


@article{llr:2017, 
title={A Standard Model of the Mind: Toward a Common Computational Framework across Artificial Intelligence, Cognitive Science, Neuroscience, and Robotics}, 
volume={38}, 
url={https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2744}, 
DOI={10.1609/aimag.v38i4.2744}, 
abstractNote={The purpose of this article is to begin the process of engaging the international research community in developing what can be called a standard model of the mind, where the mind we have in mind here is human-like. The notion of a standard model has its roots in physics, where over more than a half-century the international community has developed and tested a standard model that combines much of what is known about particles. This model is assumed to be internally consistent, yet still have major gaps. Its function is to serve as a cumulative reference point for the field while also driving efforts to both extend and break it.}, 
number={4}, 
journal={AI Magazine}, 
author={Laird, John E. and Lebiere, Christian and Rosenbloom, Paul S.}, 
year={2017}, 
month={Dec.}, 
pages={13-26} }


@misc{bubeck:2023,
      title={Sparks of Artificial General Intelligence: Early experiments with GPT-4}, 
      author={Sébastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
      year={2023},
      eprint={2303.12712},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@misc{kosinski:2023,
      title={Theory of Mind May Have Spontaneously Emerged in Large Language Models}, 
      author={Michal Kosinski},
      year={2023},
      eprint={2302.02083},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{yao:2023,
      title={ReAct: Synergizing Reasoning and Acting in Language Models}, 
      author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
      year={2023},
      eprint={2210.03629},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{diao:2023,
      title={Active Prompting with Chain-of-Thought for Large Language Models}, 
      author={Shizhe Diao and Pengcheng Wang and Yong Lin and Tong Zhang},
      year={2023},
      eprint={2302.12246},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{devlin:2019,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}


@inproceedings{brown:2020,
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1877--1901},
 publisher = {Curran Associates, Inc.},
 title = {Language Models are Few-Shot Learners},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
 volume = {33},
 year = {2020}
}


@article{li:2022,
  author       = {Shuang Li and
                  Xavier Puig and
                  Chris Paxton and
                  Yilun Du and
                  Clinton Wang and
                  Linxi Fan and
                  Tao Chen and
                  De{-}An Huang and
                  Ekin Aky{\"{u}}rek and
                  Anima Anandkumar and
                  Jacob Andreas and
                  Igor Mordatch and
                  Antonio Torralba and
                  Yuke Zhu},
  title        = {Pre-Trained Language Models for Interactive Decision-Making},
  journal      = {CoRR},
  volume       = {abs/2202.01771},
  year         = {2022},
  url          = {https://arxiv.org/abs/2202.01771},
  eprinttype    = {arXiv},
  eprint       = {2202.01771},
  timestamp    = {Tue, 02 Aug 2022 12:20:45 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2202-01771.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@misc{huang:2023,
      title={A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation}, 
      author={Xiaowei Huang and Wenjie Ruan and Wei Huang and Gaojie Jin and Yi Dong and Changshun Wu and Saddek Bensalem and Ronghui Mu and Yi Qi and Xingyu Zhao and Kaiwen Cai and Yanghao Zhang and Sihao Wu and Peipei Xu and Dengyu Wu and Andre Freitas and Mustafa A. Mustafa},
      year={2023},
      eprint={2305.11391},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{mcshane:2017, 
title={Natural Language Understanding (NLU, not NLP) in Cognitive Systems}, volume={38}, url={https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2745}, DOI={10.1609/aimag.v38i4.2745}, abstractNote={Developing cognitive agents with human-level natural language understanding (NLU) capabilities requires modeling human cognition because natural, unedited utterances regularly contain ambiguities, ellipses, production errors, implicatures, and many other types of complexities. Moreover, cognitive agents must be nimble in the face of incomplete interpretations since even people do not perfectly understand every aspect of every utterance they hear. So, once an agent has reached the best interpretation it can, it must determine how to proceed – be that acting upon the new information directly, remembering an incomplete interpretation and waiting to see what happens next, seeking out information to fill in the blanks, or asking its interlocutor for clarification. The reasoning needed to support NLU extends far beyond language itself, including, non-exhaustively, the agent’s understanding of its own plans and goals; its dynamic modeling of its interlocutor’s knowledge, plans, and goals, all guided by a theory of mind; its recognition of diverse aspects human behavior, such as affect, cooperative behavior, and the effects of cognitive biases; and its integration of linguistic interpretations with its interpretations of other perceptive inputs, such as simulated vision and non-linguistic audition. Considering all of these needs, it seems hardly possible that fundamental NLU will ever be achieved through the kinds of knowledge-lean text-string manipulation being pursued by the mainstream natural language processing (NLP) community. Instead, it requires a holistic approach to cognitive modeling of the type we are pursuing in a paradigm called OntoAgent.}, number={4}, journal={AI Magazine}, author={McShane, Marjorie}, year={2017}, month={Dec.}, pages={43-56} }


@article{marcus:2020,
  author       = {Gary Marcus},
  title        = {The Next Decade in {AI:} Four Steps Towards Robust Artificial Intelligence},
  journal      = {CoRR},
  volume       = {abs/2002.06177},
  year         = {2020},
  url          = {https://arxiv.org/abs/2002.06177},
  eprinttype    = {arXiv},
  eprint       = {2002.06177},
  timestamp    = {Thu, 13 Apr 2023 19:55:39 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2002-06177.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{park:2023,
      title={Generative Agents: Interactive Simulacra of Human Behavior}, 
      author={Joon Sung Park and Joseph C. O'Brien and Carrie J. Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein},
      year={2023},
      eprint={2304.03442},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}


@misc{mialon:2023,
      title={Augmented Language Models: a Survey}, 
      author={Grégoire Mialon and Roberto Dessì and Maria Lomeli and Christoforos Nalmpantis and Ram Pasunuru and Roberta Raileanu and Baptiste Rozière and Timo Schick and Jane Dwivedi-Yu and Asli Celikyilmaz and Edouard Grave and Yann LeCun and Thomas Scialom},
      year={2023},
      eprint={2302.07842},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{wei:2023,
  author       = {Jason Wei and
                  Xuezhi Wang and
                  Dale Schuurmans and
                  Maarten Bosma and
                  Ed H. Chi and
                  Quoc Le and
                  Denny Zhou},
  title        = {Chain of Thought Prompting Elicits Reasoning in Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2201.11903},
  year         = {2022},
  url          = {https://arxiv.org/abs/2201.11903},
  eprinttype    = {arXiv},
  eprint       = {2201.11903},
  timestamp    = {Fri, 22 Apr 2022 16:06:31 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2201-11903.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{gao:2023,
      title={PAL: Program-aided Language Models}, 
      author={Luyu Gao and Aman Madaan and Shuyan Zhou and Uri Alon and Pengfei Liu and Yiming Yang and Jamie Callan and Graham Neubig},
      year={2023},
      eprint={2211.10435},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{schick:2023,
      title={Toolformer: Language Models Can Teach Themselves to Use Tools}, 
      author={Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
      year={2023},
      eprint={2302.04761},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{xie:2023,
      title={OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities}, 
      author={Yuanzhen Xie and Tao Xie and Mingxiong Lin and WenTao Wei and Chenglin Li and Beibei Kong and Lei Chen and Chengxiang Zhuo and Bo Hu and Zang Li},
      year={2023},
      eprint={2305.16334},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@book{em:86,
  editor  = "Engelmore, Robert and Morgan, Anthony",
  title   = "Blackboard Systems",
  year    = 1986,
  address = "Reading, Mass.",
  publisher = "Addison-Wesley",
}

@inproceedings{c:83,
  author  = "Clancey, William J.",
  year    = 1983,
  title   = "{Communication, Simulation, and Intelligent
Agents: Implications of Personal Intelligent Machines
for Medical Education}",
  booktitle="Proceedings of the Eighth International Joint Conference on Artificial Intelligence {(IJCAI-83)}", 
  pages   = "556-560",
  address = "Menlo Park, Calif",
  publisher = "{IJCAI Organization}",
}
@inproceedings{c:84,
  author  = "Clancey, William J.",
  year    = 1984,
  title   = "{Classification Problem Solving}",
  booktitle = "Proceedings of the Fourth National 
              Conference on Artificial Intelligence",
  pages   = "45-54",
  address = "Menlo Park, Calif.",
  publisher="AAAI Press",
}
@article{r:80,
  author = {Robinson, Arthur L.},
  title = {New Ways to Make Microcircuits Smaller},
  volume = {208},
  number = {4447},
  pages = {1019--1022},
  year = {1980},
  doi = {10.1126/science.208.4447.1019},
  publisher = {American Association for the Advancement of Science},
  issn = {0036-8075},
  URL = {https://science.sciencemag.org/content/208/4447/1019},
  eprint = {https://science.sciencemag.org/content/208/4447/1019.full.pdf},
  journal = {Science},
}
@article{r:80x,
  author  = "Robinson, Arthur L.",
  year    = 1980,
  title   = "{New Ways to Make Microcircuits Smaller---Duplicate Entry}",
  journal = "Science",
  volume  =  208,
  pages   = "1019-1026",
}
@article{hcr:83,
title = {Strategic explanations for a diagnostic consultation system},
journal = {International Journal of Man-Machine Studies},
volume = {20},
number = {1},
pages = {3-19},
year = {1984},
issn = {0020-7373},
doi = {https://doi.org/10.1016/S0020-7373(84)80003-6},
url = {https://www.sciencedirect.com/science/article/pii/S0020737384800036},
author = {Diane Warner Hasling and William J. Clancey and Glenn Rennels},
abstract = {This article examines the problem of automatte explanation of reasoning, especially as it relates to expert systems. By explanation we mean the ability of a program to discuss what it is doing in some understandable way. We first present a general framework in which to view explanation and review some of the research done in this area. We then focus on the explanation system for NEOMYCIN, a medical consultation program. A consultation program interactively helps a user to solve a problem. Our goal is to have NEOMYCIN explain its problem-solving strategies. An explanation of strategy describes the plan the program is using to reach a solution. Such an explanation is usually concrete, referring to aspects of the current problem situation. Abstract explanations articulate a general principle, which can be applied in different situations; such explanations are useful in teaching and in explaining by analogy. We describe the aspects of NEOMYCIN that make abstract strategic explanations possible—the representation of strategic knowledge explicitly and separately from domain knowledge— and demonstrate how this representation can be used to generate explanations.}
}
@article{hcrt:83,
  author  = "Hasling, Diane Warner and Clancey, William J. and Rennels, Glenn R. and Test, Thomas",
  year    = 1983,
  title   = "{Strategic Explanations in Consultation---Duplicate}",
  journal = "The International Journal of Man-Machine Studies",
  volume  = 20,
  number  = 1,
  pages   = "3-19",
}
@techreport{r:86,
  author  = "Rice, James",
  year    = 1986,
  title   = "{Poligon: A System for Parallel Problem Solving}",
  type    = "Technical Report", 
  number  = "KSL-86-19", 
  institution = "Dept.\ of Computer Science, Stanford Univ.",
}
@phdthesis{c:79,
  author  = "Clancey, William J.",
  year    = 1979,
  title   = "{Transfer of Rule-Based Expertise
through a Tutorial Dialogue}",
  type    = "{Ph.D.} diss.",
  school  = "Dept.\ of Computer Science, Stanford Univ.",
  address = "Stanford, Calif.",
}
@unpublished{c:21,
  author  = "Clancey, William J.",
  title   = "{The Engineering of Qualitative Models}",
  year    = 2021,
  note    = "Forthcoming",
}
@misc{c:22,
      title={Crime and punishment in scientific research}, 
      author={Mathieu Bouville},
      year={2008},
      eprint={0803.4058},
      archivePrefix={arXiv},
      primaryClass={physics.soc-ph}
}
@misc{c:23,
  title        = "Pluto: The 'Other' Red Planet",
  author       = "{NASA}",
  howpublished = "\url{https://www.nasa.gov/nh/pluto-the-other-red-planet}",
  year         = 2015,
  note         = "Accessed: 2018-12-06"
}

@inproceedings{mitsopoulos_pvgas_2023,
    title = {Psychologically-Valid Generative Agents: A Novel Approach to Agent-Based Modeling in Social Sciences},
    booktitle = {Proceedings of the 2023 {AAAI} Fall Symposium on Integrating Cognitive Architectures and Generative Models},
    author = {Mitsopoulos, Konstantinos and Bose, Rik and Mather, Brodie and Bhatia, Archna and Gluck, Kevin and Dorr, Bonnie and Lebiere, Christian and Pirolli, Peter},
    year = {2023},
    publisher= {AAAI Press},
}
 

